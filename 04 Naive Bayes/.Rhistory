# Upload data set
name <- file.choose()
data <- read.csv(name, header = TRUE, na.strings = '?')
View(data)
# Summary data, see the overall of input data
summary(data)
# Identify missing values
missing_values <- is.na(data)
missing_values
# Remove the rows with missing values
data <- na.omit(data)
# Convert diagnosis class, 2 for "Benign" and 4 for "Malignant"
data$Class<- factor(data$Class , levels = c("2","4") , labels = c("Benign","Malignant"))
# load the necessary packages
library(e1071)
library(class)
# Split data into 2 parts: 70% as training data, and 30% as testing data
split_data <- sample(1:nrow(data), 0.7 * nrow(data))
cl_data <- data['Class']
train_data <- normalized_data[split_data, ]
test_data <- normalized_data[-split_data, ]
rm(list=ls())
# Upload data set
name <- file.choose()
data <- read.csv(name, header = TRUE, na.strings = '?')
View(data)
# Summary data, see the overall of input data
summary(data)
# Identify missing values
missing_values <- is.na(data)
missing_values
# Remove the rows with missing values
data <- na.omit(data)
# Convert diagnosis class, 2 for "Benign" and 4 for "Malignant"
data$Class<- factor(data$Class , levels = c("2","4") , labels = c("Benign","Malignant"))
# load the necessary packages
library(e1071)
library(class)
# Split data into 2 parts: 70% as training data, and 30% as testing data
split_data <- sample(1:nrow(data), 0.7 * nrow(data))
cl_data <- data['Class']
train_data <- normalized_data[split_data, ]
test_data <- normalized_data[-split_data, ]
# Implement naiveBayes function
model_naiveBayes <- naiveBayes(Class ~ ., data = train_data)
rm(list=ls())
# Upload data set
name <- file.choose()
data <- read.csv(name, header = TRUE, na.strings = '?')
View(data)
# Summary data, see the overall of input data
summary(data)
# Identify missing values
missing_values <- is.na(data)
missing_values
# Remove the rows with missing values
data <- na.omit(data)
# Convert diagnosis class, 2 for "Benign" and 4 for "Malignant"
data$Class<- factor(data$Class , levels = c("2","4") , labels = c("Benign","Malignant"))
# load the necessary packages
library(e1071)
library(class)
# Split data into 2 parts: 70% as training data, and 30% as testing data
split_data <- sample(1:nrow(data), 0.7 * nrow(data))
train_data <- data[split_data, ]
test_data <- data[-split_data, ]
# Implement naiveBayes function
model_naiveBayes <- naiveBayes(Class ~ ., data = train_data)
# Predict target class using predict function
predict_naiveBayes <- predict(model_naiveBayes, test_data)
# Create a confusion matrix
confusion_matrix <- table(predict_nb = predict_naiveBayes, class = test_data$Class)
print(confusion_matrix)
# Compute accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(confusion_matrix)
# Compute error rate
error_rate <- sum(model_naiveBayes != test_data$Class) / length(test_data$Class)
cat("Error rate:", error_rate * 100, "%\n")
View(model_naiveBayes)
View(predict_naiveBayes)
rm(list=ls())
# Upload data set
name <- file.choose()
data <- read.csv(name, header = TRUE, na.strings = '?')
View(data)
# Summary data, see the overall of input data
summary(data)
# Identify missing values
missing_values <- is.na(data)
missing_values
# Remove the rows with missing values
data <- na.omit(data)
# Convert diagnosis class, 2 for "Benign" and 4 for "Malignant"
data$Class<- factor(data$Class , levels = c("2","4") , labels = c("Benign","Malignant"))
# load the necessary packages
library(e1071)
library(class)
# Split data into 2 parts: 70% as training data, and 30% as testing data
split_data <- sample(1:nrow(data), 0.7 * nrow(data))
train_data <- data[split_data, ]
test_data <- data[-split_data, ]
# Implement naiveBayes function
model_naiveBayes <- naiveBayes(Class ~ ., data = train_data)
View(model_naiveBayes)
# Predict target class using predict function
predict_naiveBayes <- predict(model_naiveBayes, test_data)
View(predict_naiveBayes)
# Create a confusion matrix
confution_matrix <- confusionMatrix(predict_naiveBayes, test_data$Class)
library(caret)
# Evaluate the model
table(nbPredictions, testData$Species)
# Evaluate the model
table(predict_naiveBayes, test_data$Class)
# Evaluate the model
table(predict_naiveBayes, test_data$Class)
# Compute error rate
error_rate <- sum(model_naiveBayes != test_data$Class) / length(test_data$Class)
cat("Error rate:", error_rate * 100, "%\n")
rm(list=ls())
library(e1071)
library(class)
csvfile<-file.choose()
Titanic_rows<-  read.csv(csvfile)
View(Titanic_rows)
class(Titanic_rows)
prop.table
table(class=Titanic_rows$Class,Survival=Titanic_rows$Survived)
prop.table(table(Class=Titanic_rows$Class,Survived=Titanic_rows$Survived))
## Naive Bayes classification using only one variable
nBayes_class <- naiveBayes(Survived ~Class, data =Titanic_rows)
category_class<-predict(nBayes_class,Titanic_rows  )
View(category_class)
## Compare the prediction to actual
data_class<-cbind(Titanic_rows,category_class)
table(Class=Titanic_rows$Class,Survived=Titanic_rows$Survived)
table(Class=Titanic_rows$Class,NBayes=category_class)
table(NBayes=category_class,Survived=Titanic_rows$Survived)
prop.table(table(Class=Titanic_rows$Class,Survived=Titanic_rows$Survived))
## Naive Bayes classification using two variables
nBayes_class_age <- naiveBayes(Survived ~Class+Age, data =Titanic_rows)
category_class_age<-predict(nBayes_class_age,Titanic_rows  )
## Compare the prediction to actual for two variables
table(Class=Titanic_rows$Class,Survived=Titanic_rows$Survived)
ftable(Class=Titanic_rows$Class,Titanic_rows$Age,Survived=Titanic_rows$Survived,NBayes=category_class_age,row.vars = 1:3)
ftable(Class=Titanic_rows$Class,Titanic_rows$Age,Survived=Titanic_rows$Survived,NBayes=category_class_age)
ftable(Class=Titanic_rows$Class,Titanic_rows$Age,Survived=Titanic_rows$Survived)
nBayes_all <- naiveBayes(Survived ~., data =Titanic_rows)
category_all<-predict(nBayes_all,Titanic_rows  )
table(NBayes_all=category_all,Survived=Titanic_rows$Survived)
NB_wrong<-sum(category_all!=Titanic_rows$Survived)
NB_error_rate<-NB_wrong/length(category_all)
rm(list=ls())
# Upload data set
name <- file.choose()
data <- read.csv(name, header = TRUE, na.strings = '?')
View(data)
# Summary data, see the overall of input data
summary(data)
# Identify missing values
missing_values <- is.na(data)
missing_values
# Remove the rows with missing values
data <- na.omit(data)
# Convert diagnosis class, 2 for "Benign" and 4 for "Malignant"
data$Class<- factor(data$Class , levels = c("2","4") , labels = c("Benign","Malignant"))
# load the necessary packages
library(e1071)
library(class)
# Split data into 2 parts: 70% as training data, and 30% as testing data
split_data <- sample(1:nrow(data), 0.7 * nrow(data))
train_data <- data[split_data, ]
test_data <- data[-split_data, ]
# Implement naiveBayes function
model_naiveBayes <- naiveBayes(Class ~ ., data = train_data)
# Predict target class using predict function
predict_naiveBayes <- predict(model_naiveBayes, test_data)
# Compare the prediction to actual for two variables
table(predict_naiveBayes, test_data$Class)
# Compare the prediction to actual for two variables
table(predict_naiveBayes, test_data)
# Compare the prediction to actual for two variables
table(predict_naiveBayes, test_data$Class)
rm(list=ls())
library(e1071)
library(class)
csvfile<-file.choose()
Titanic_rows<-  read.csv(csvfile)
View(Titanic_rows)
class(Titanic_rows)
table(class=Titanic_rows$Class,Survival=Titanic_rows$Survived)
prop.table(table(Class=Titanic_rows$Class,Survived=Titanic_rows$Survived))
## Naive Bayes classification using only one variable
nBayes_class <- naiveBayes(Survived ~Class, data =Titanic_rows)
View(nBayes_class)
table(nBayes_class)
print(nBayes_class)
category_class<-predict(nBayes_class, Titanic_rows)
print(category_class)
## Compare the prediction to actual
data_class<-cbind(Titanic_rows,category_class)
print(data_class)
table(Class=Titanic_rows$Class,Survived=Titanic_rows$Survived)
table(Class=Titanic_rows$Class,NBayes=category_class)
table(NBayes=category_class,Survived=Titanic_rows$Survived)
prop.table(table(Class=Titanic_rows$Class,Survived=Titanic_rows$Survived))
## Naive Bayes classification using two variables
nBayes_class_age <- naiveBayes(Survived ~Class+Age, data =Titanic_rows)
print(nBayes_class_age)
category_class_age<-predict(nBayes_class_age,Titanic_rows  )
print(category_class_age)
## Compare the prediction to actual for two variables
table(Class=Titanic_rows$Class,Survived=Titanic_rows$Survived)
ftable(Class=Titanic_rows$Class,Titanic_rows$Age,Survived=Titanic_rows$Survived,NBayes=category_class_age,row.vars = 1:3)
ftable(Class=Titanic_rows$Class,Titanic_rows$Age,Survived=Titanic_rows$Survived,NBayes=category_class_age,row.vars = 1:2)
ftable(Class=Titanic_rows$Class,Titanic_rows$Age,Survived=Titanic_rows$Survived,NBayes=category_class_age,row.vars = 1:1)
ftable(Class=Titanic_rows$Class,Titanic_rows$Age,Survived=Titanic_rows$Survived,NBayes=category_class_age,row.vars = 1:3)
ftable(Class=Titanic_rows$Class,Titanic_rows$Age,Survived=Titanic_rows$Survived,NBayes=category_class_age,row.vars = 1:4)
ftable(Class=Titanic_rows$Class,Titanic_rows$Age,Survived=Titanic_rows$Survived,NBayes=category_class_age,row.vars = 1:3)
ftable(Class=Titanic_rows$Class,Titanic_rows$Age,Survived=Titanic_rows$Survived,NBayes=category_class_age)
ftable(Class=Titanic_rows$Class,Titanic_rows$Age,Survived=Titanic_rows$Survived)
ftable(class=Titanic_rows$Class,Age=Titanic_rows$Age,Sex=Titanic_rows$Sex,
Survival=Titanic_rows$Survived,row.vars = 1:3)
prop.table(
ftable(class=Titanic_rows$Class,Age=Titanic_rows$Age,Sex=Titanic_rows$Sex,
Survival=Titanic_rows$Survived,row.vars = 1:3)
)
nBayes_all <- naiveBayes(Survived ~., data =Titanic_rows)
category_all<-predict(nBayes_all,Titanic_rows  )
print(nBayes_all)
table(NBayes_all=category_all,Survived=Titanic_rows$Survived)
table(NBayes_all=category_all,Survived=Titanic_rows$Age)
table(NBayes_all=category_all,Survived=Titanic_rows$Survived)
nBayes_all <- naiveBayes(Sex ~., data =Titanic_rows)
print(nBayes_a)
print(nBayes_all)
print(nBayes_all)
category_all<-predict(nBayes_all,Titanic_rows  )
table(NBayes_all=category_all,Survived=Titanic_rows$Survived)
# Compare the prediction t
table(predict_naiveBayes, test_data$Class)
rm(list=ls())
# Upload data set
name <- file.choose()
data <- read.csv(name, header = TRUE, na.strings = '?')
View(data)
# Summary data, see the overall of input data
summary(data)
# Identify missing values
missing_values <- is.na(data)
missing_values
# Remove the rows with missing values
data <- na.omit(data)
# Convert diagnosis class, 2 for "Benign" and 4 for "Malignant"
data$Class<- factor(data$Class , levels = c("2","4") , labels = c("Benign","Malignant"))
# load the necessary packages
library(e1071)
library(class)
# Split data into 2 parts: 70% as training data, and 30% as testing data
split_data <- sample(1:nrow(data), 0.7 * nrow(data))
train_data <- data[split_data, ]
test_data <- data[-split_data, ]
# Implement naiveBayes function
model_naiveBayes <- naiveBayes(Class ~ ., data = train_data)
# Predict target class using predict function
predict_naiveBayes <- predict(model_naiveBayes, test_data)
# Compare the prediction t
table(predict_naiveBayes, test_data$Class)
ftable(Features=test_data$col[2:10],test_data$Class,NaivesBayes=predict_naiveBayes)
ftable(Features=test_data$cols[2:10],test_data$Class,NaivesBayes=predict_naiveBayes)
ftable(Features=test_data$F1,test_data$Class,NaivesBayes=predict_naiveBayes)
# Compare the prediction t
table(predict_naiveBayes, test_data$Class)
table(test_data, test_data$Class)
# Create a confusion matrix
confusion_matrix <- table(predict_naiveBayes = predict_naiveBayes, class = test_data$Class)
print(confusion_matrix)
# Compute accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(confusion_matrix)
# Compute error rate
naiveBayes_error <- sum(predict_naiveBayes!=test_data$Class)
# Compute error rate
naiveBayes_error <- sum(predict_naiveBayes!=test_data$Class)/length(predict_naiveBayes)
print(naiveBayes_error)
print(naiveBayes_error * 100)
rm(list=ls())
