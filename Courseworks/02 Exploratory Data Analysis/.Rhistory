print(confusion_matrix)
# Accuracy for k = 10
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(confusion_matrix)
View(data)
rm(list=ls())
# Upload data set
name <- file.choose()
data <- read.csv(name, header = TRUE, na.strings = '?')
View(data)
# Identify missing values
missing_values <- is.na(data)
missing_values
# Remove the rows with missing values
data <- na.omit(data)
# Convert diagnosis class, 2 for "Benign" and 4 for "Malignant"
data$Class<- factor(data$Class , levels = c("2","4") , labels = c("Benign","Malignant"))
set.seed(123)
# Normalize data
normalized_data <- apply(data[, 2:10], 2, function(x) (x - min(x)) / (max(x) - min(x)))
View(normalized_data)
# Split data as Train data and Test data
split_data <- sample(1:nrow(data), 0.7 * nrow(data))
train_data <- normalized_data[split_data, ]
data_2 <- data['Class']
cl_train_data <- data_2[split_data, ]
test_data <- normalized_data[-split_data, ]
cl_test_data <- data_2[-split_data, ]
# load the package class
library(class)
# KNN for k = 3
knn_3 <- knn(train_data, test_data, cl=cl_train_data, k=3)
# Confusion matrix for k = 3
confusion_matrix <- table(knn_3, cl_test_data)
print(confusion_matrix)
# Accuracy for k = 3
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(confusion_matrix)
# KNN for k = 5
knn_5 <- knn(train_data, test_data, cl=cl_train_data, k=5)
# Confusion matrix for k = 5
confusion_matrix <- table(knn_5, cl_test_data)
print(confusion_matrix)
# Accuracy for k = 5
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(confusion_matrix)
# KNN for k = 10
knn_10 <- knn(train_data, test_data, cl=cl_train_data, k=3)
# Confusion matrix for k = 10
confusion_matrix <- table(knn_10, cl_test_data)
print(confusion_matrix)
# Accuracy for k = 10
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
rm(list=ls())
library(caret)
install.packages("caret")
library(caret)
rm(list=ls())
# Upload data set
name <- file.choose()
data <- read.csv(name, header = TRUE, na.strings = '?')
View(data)
# Identify missing values
missing_values <- is.na(data)
missing_values
# Remove the rows with missing values
data <- na.omit(data)
# Convert diagnosis class, 2 for "Benign" and 4 for "Malignant"
data$Class<- factor(data$Class , levels = c("2","4") , labels = c("Benign","Malignant"))
# Normalize data
normalized_data <- apply(data[, 2:10], 2, function(x) (x - min(x)) / (max(x) - min(x)))
View(normalized_data)
# Split data as Train data and Test data
split_data <- sample(1:nrow(data), 0.7 * nrow(data))
train_data <- normalized_data[split_data, ]
data_2 <- data['Class']
cl_train_data <- data_2[split_data, ]
test_data <- normalized_data[-split_data, ]
cl_test_data <- data_2[-split_data, ]
# load the package class
library(class)
install.packages("caret")
library(caret)
# KNN for k = 3
knn_3 <- knn(train_data, test_data, cl=cl_train_data, k=3)
# Confusion matrix for k = 3
confusion_matrix <- table(knn_3, cl_test_data)
print(confusion_matrix)
# Accuracy for k = 3
# accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy <- confusionMatrix(knn_3, cl_test_data)
print(accuracy)
rint(accuracy$overall['Accuracy'])
print(accuracy$overall['Accuracy'])
View(accuracy)
print(accuracy$overall['Accuracy'] * 100)
print(accuracy$overall['Accuracy'] * 100, '%')
cat(accuracy$overall['Accuracy'] * 100)
cat(accuracy$overall['Accuracy'] * 100, '%')
cat("Accuracy: ", accuracy$overall['Accuracy'] * 100, '%')
rm(list=ls())
# Upload data set
name <- file.choose()
# Upload data set
name <- file.choose()
data <- read.csv(name, header = TRUE, na.strings = '?')
View(data)
# Summary data
summary(data)
# Identify missing values
missing_values <- is.na(data)
missing_values
# Remove the rows with missing values
data <- na.omit(data)
# Convert diagnosis class, 2 for "Benign" and 4 for "Malignant"
data$Class<- factor(data$Class , levels = c("2","4") , labels = c("Benign","Malignant"))
# KNN Methodology
# Normalize data
normalized_data <- apply(data[, 2:10], 2, function(x) (x - min(x)) / (max(x) - min(x)))
View(normalized_data)
# Split data into 2 parts: 70% as training data, and 30% as testing data
split_data <- sample(1:nrow(data), 0.7 * nrow(data))
cl_data <- data['Class']
train_data <- normalized_data[split_data, ]
cl_train_data <- cl_data[split_data, ]
test_data <- normalized_data[-split_data, ]
cl_test_data <- cl_data[-split_data, ]
# load the necessary packages
library(class)
for (k in [3, 5, 10]){
# Convert diagnosis class, 2 for "Benign" and 4 for "Malignant"
data$Class<- factor(data$Class , levels = c("2","4") , labels = c("Benign","Malignant"))
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix: ", confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k = ", k, ": ", accuracy(confusion_matrix))
}
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
print("Confusion Matrix:")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k = ", k, ":")
print(accuracy(confusion_matrix))
}
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix:")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":")
accuracy(confusion_matrix)
}
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix:")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix))
accuracy(confusion_matrix)
}
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix:")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "\n")
}
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix:\n")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "\n")
}
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n\n")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "\n\n")
}
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n\n")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("\nAccuracy for k =", k, ":", accuracy(confusion_matrix), "\n\n")
}
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n\n")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("\nAccuracy for k =", k, ":", accuracy(confusion_matrix), " %\n\n")
}
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n\n")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("\nAccuracy for k =", k, ":", accuracy(confusion_matrix), "%\n\n")
}
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n\n")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("\nAccuracy for k =", k, ":", accuracy(confusion_matrix), "%\n\n\n")
}
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("\nAccuracy for k =", k, ":", accuracy(confusion_matrix), "%\n\n\n")
}
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "%\n\n")
}
# Doing KNN methodology and evaluate the result for k = 3, 5, and 10
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "%\n\n")
predicted_labels <- knn(train_data, test_data, knn_k, k = k, cl = cl_train_data)
error_rate <- sum(predicted_labels != cl_test_data) / length(cl_test_data)
cat("Error rate:", error_rate)
}
# Doing KNN methodology and evaluate the result for k = 3, 5, and 10
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "%\n\n")
predicted_labels <- knn(train_data, test_data, knn_k, k = k, cl = cl_train_data)
error_rate <- sum(predicted_labels != cl_test_data) / length(cl_test_data)
cat("Error rate:", error_rate * 100)
}
# Doing KNN methodology and evaluate the result for k = 3, 5, and 10
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "%\n")
predicted_labels <- knn(train_data, test_data, knn_k, k = k, cl = cl_train_data)
error_rate <- sum(predicted_labels != cl_test_data) / length(cl_test_data)
cat("\nError rate:", error_rate * 100)
}
# Doing KNN methodology and evaluate the result for k = 3, 5, and 10
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "%\n")
predicted_labels <- knn(train_data, test_data, knn_k, k = k, cl = cl_train_data)
error_rate <- sum(predicted_labels != cl_test_data) / length(cl_test_data)
cat("Error rate:", error_rate * 100, "\n")
}
cat("Error rate:", error_rate * 100, "%\n")
# Doing KNN methodology and evaluate the result for k = 3, 5, and 10
for (k in c(3, 5, 10)){
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "%\n")
predicted_labels <- knn(train_data, test_data, knn_k, k = k, cl = cl_train_data)
error_rate <- sum(predicted_labels != cl_test_data) / length(cl_test_data)
cat("Error rate:", error_rate * 100, "%\n")
}
# Doing KNN methodology and evaluate the result for k = 3, 5, and 10
for (k in c(3, 5, 10)){
# KNN function for each k
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
# Create confusion matrix
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
# Compute accuracy
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "%\n")
# Compute error rate
prediction <- knn(train_data, test_data, knn_k, k = k, cl = cl_train_data)
error_rate <- sum(knn_k != cl_test_data) / length(cl_test_data)
cat("Error rate:", error_rate * 100, "%\n")
}
print(length(cl_test_data))
print(length(cl_train_data))
print(length(cl_train_data))
print(length(cl_test_data))
View(cl_train_data)
# Doing KNN methodology and evaluate the result for k = 3, 5, and 10
for (k in c(3, 5, 10)){
# KNN function for each k
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
# Create confusion matrix
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
# Compute accuracy
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "%\n")
# Compute error rate
error_rate <- sum(knn_k != cl_test_data) / length(cl_test_data)
cat("Error rate:", error_rate * 100, "%\n")
# Create a data frame with the predicted and true labels
results <- data.frame(predicted = knn_k, true = cl_test_data, data_type = "Test")
# Create a data frame with the training labels
train_results <- data.frame(predicted = knn_k, true = cl_train_data, data_type = "Train")
# Combine the two data frames
all_results <- rbind(results, train_results)
# Plot a scatterplot with the predicted and true labels, colored by data type
ggplot(all_results, aes(x = Sepal.Length, y = Sepal.Width, color = predicted)) +
geom_point(aes(shape = true), size = 3) +
ggtitle(paste("k-NN Classification Results (k = 5)\nError Rate:", error_rate))
}
View(knn_k)
print(knn_k)
results <- data.frame(predicted = predicted_labels, true = test_labels, data_type = "Test")
results <- data.frame(predicted = knn_k, true = cl_test_data, data_type = "Test")
print(results)
train_results <- data.frame(predicted = knn_k, true = cl_train_data, data_type = "Train")
print(cl_train_data)
print(train_data)
train_results <- data.frame(predicted = knn_k[cl_train_data], true = cl_train_data, data_type = "Train")
all_results <- rbind(results, train_results)
print(all_results)
ggplot(all_results, aes(x = Sepal.Length, y = Sepal.Width, color = predicted)) +
geom_point(aes(shape = true), size = 3) +
ggtitle(paste("k-NN Classification Results (k = 5)\nError Rate:", error_rate))
ggplot(all_results, aes(x = 'Benign', y = 'Malignant', color = predicted)) +
geom_point(aes(shape = true), size = 3) +
ggtitle(paste("k-NN Classification Results (k = 5)\nError Rate:", error_rate))
# Doing KNN methodology and evaluate the result for k = 3, 5, and 10
for (k in c(3, 5, 10)){
# KNN function for each k
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
# Create confusion matrix
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
# Compute accuracy
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "%\n")
# Compute error rate
error_rate <- sum(knn_k != cl_test_data) / length(cl_test_data)
cat("Error rate:", error_rate * 100, "%\n")
pairs(knn_k, main = "test", pch = 20)
}
pairs(all_results, main = "Scatter plot of F1 to F6", pch = 20)
rm(list=ls())
# Upload data set
name <- file.choose()
data <- read.csv(name, header = TRUE, na.strings = '?')
View(data)
# Summary data, see the overall of input data
summary(data)
# Identify missing values
missing_values <- is.na(data)
missing_values
# Remove the rows with missing values
data <- na.omit(data)
# Convert diagnosis class, 2 for "Benign" and 4 for "Malignant"
data$Class<- factor(data$Class , levels = c("2","4") , labels = c("Benign","Malignant"))
# KNN Methodology
# Normalize data
normalized_data <- apply(data[, 2:10], 2, function(x) (x - min(x)) / (max(x) - min(x)))
View(normalized_data)
# Split data into 2 parts: 70% as training data, and 30% as testing data
split_data <- sample(1:nrow(data), 0.7 * nrow(data))
cl_data <- data['Class']
train_data <- normalized_data[split_data, ]
cl_train_data <- cl_data[split_data, ]
test_data <- normalized_data[-split_data, ]
cl_test_data <- cl_data[-split_data, ]
# load the necessary packages
library(class)
# Doing KNN methodology and evaluate the result for k = 3, 5, and 10
for (k in c(3, 5, 10)){
# KNN function for each k
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
# Create confusion matrix
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
# Compute accuracy
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "%\n")
# Compute error rate
error_rate <- sum(knn_k != cl_test_data) / length(cl_test_data)
cat("Error rate:", error_rate * 100, "%\n")
}
# Doing KNN methodology and evaluate the result for k = 3, 5, and 10
for (k in c(3, 5, 10)){
# KNN function for each k
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
# Create confusion matrix
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
# Compute accuracy
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "%\n")
# Compute error rate
error_rate <- sum(knn_k != cl_test_data) / length(cl_test_data)
cat("Error rate:", error_rate * 100, "%\n")
}
# Doing KNN methodology and evaluate the result for k = 3, 5, and 10
for (k in c(3, 5, 10)){
# KNN function for each k
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
# Create confusion matrix
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
# Compute accuracy
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "%\n")
# Compute error rate
error_rate <- sum(knn_k != cl_test_data) / length(cl_test_data)
cat("Error rate:", error_rate * 100, "%\n")
}
# Doing KNN methodology and evaluate the result for k = 3, 5, and 10
for (k in c(3, 5, 10)){
# KNN function for each k
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
# Create confusion matrix
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
# Compute accuracy
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "%\n")
# Compute error rate
error_rate <- sum(knn_k != cl_test_data) / length(cl_test_data)
cat("Error rate:", error_rate * 100, "%\n")
}
# Doing KNN methodology and evaluate the result for k = 3, 5, and 10
for (k in c(3, 5, 10)){
# KNN function for each k
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
# Create confusion matrix
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
# Compute accuracy
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "%\n")
# Compute error rate
error_rate <- sum(knn_k != cl_test_data) / length(cl_test_data)
cat("Error rate:", error_rate * 100, "%\n")
}
# Doing KNN methodology and evaluate the result for k = 3, 5, and 10
for (k in c(3, 5, 10)){
# KNN function for each k
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
# Create confusion matrix
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
# Compute accuracy
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "%\n")
# Compute error rate
error_rate <- sum(knn_k != cl_test_data) / length(cl_test_data)
cat("Error rate:", error_rate * 100, "%\n")
}
# Doing KNN methodology and evaluate the result for k = 3, 5, and 10
for (k in c(3, 5, 10)){
# KNN function for each k
knn_k <- knn(train_data, test_data, cl=cl_train_data, k=k)
# Create confusion matrix
confusion_matrix <- table(knn_k, cl_test_data)
cat("Confusion Matrix for k =", k, ":\n")
print(confusion_matrix)
# Compute accuracy
accuracy <- function(x) {sum(diag(x)/(sum(rowSums(x)))) * 100}
cat("Accuracy for k =", k, ":", accuracy(confusion_matrix), "%\n")
# Compute error rate
error_rate <- sum(knn_k != cl_test_data) / length(cl_test_data)
cat("Error rate:", error_rate * 100, "%\n")
}
rm(list=ls())
